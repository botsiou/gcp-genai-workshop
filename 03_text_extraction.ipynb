{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Text Extraction with Generative Models on Vertex AI \n",
    "\n",
    "_The last part of this lab requires access to [DocAI API](https://console.cloud.google.com/ai/document-ai)._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Text extraction is a process of extracting text from a document. This can be done manually or automatically. Manual text extraction is the process of reading the document and copying the text into a new document. Automatic text extraction is the process of using software to extract the text from the document.\n",
    "\n",
    "Text extraction can be used for a variety of purposes. One common purpose is to convert documents into a machine-readable format. This can be useful for storing documents in a database or for processing documents with software. Another common purpose is to extract information from documents. This can be useful for finding specific information in a document or for summarizing the content of a document.\n",
    "\n",
    "Large language models (LLMs) are good for text extraction because they are trained on massive datasets of text and code, which allows them to learn the relationships between words and phrases. They can also understand the context of text and generate text, which allows them to extract information that is not explicitly stated or fill in the gaps in text that is missing information. The answers from LLMs can also be further improved through methods like few-shot prompting.\n",
    "\n",
    "Learn more about extraction prompts in the [official documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/text/extraction-prompts)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you will learn how to use generative models to extract the information from text by working through the following examples:\n",
    "- Google Pixel technical specifications extraction\n",
    "- WiFi troubleshooting with constraints\n",
    "- Respond to inquiries in character\n",
    "- Converting an ingredients list to JSON format\n",
    "- Organizing the results of a text extraction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aed92deeb4a0"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xoMiNbiCDM2w"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Install Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "148dd6321946"
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform google-cloud-core google-cloud-documentai google-cloud-storage simplejson --upgrade --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FLVWFKFwkLKE"
   },
   "source": [
    "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab only:** Uncomment the following cell to initialize the Vertex AI SDK. For Vertex AI Workbench, you don't need to run this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vertexai\n",
    "\n",
    "# PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "# vertexai.init(project=PROJECT_ID, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai  # type: ignore\n",
    "from typing import Optional\n",
    "\n",
    "from vertexai.preview.language_models import TextGenerationModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wbll-sxLD58J"
   },
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "H_uxqUPADM2z"
   },
   "source": [
    "### Google Pixel technical specifications extraction\n",
    "\n",
    "In this example, you try to extract the technical specifications of a Pixel phone from text in JSON format using the PaLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "-T5drTkzDM2z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"product\":\"Google Pixel 7\",\n",
      "  \"network\":\"5G\",\n",
      "  \"RAM\":\"8GB\",\n",
      "  \"processor\":\"Tensor G2\",\n",
      "  \"storage\":\"128GB\",\n",
      "  \"color\":\"Lemongrass\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Extract the technical specifications from the text below in JSON format.\n",
    "\n",
    "Text: Google Nest WiFi, network speed up to 1200Mpbs, 2.4GHz and 5GHz frequencies, WP3 protocol\n",
    "JSON: {\n",
    "  \"product\":\"Google Nest WiFi\",\n",
    "  \"speed\":\"1200Mpbs\",\n",
    "  \"frequencies\": [\"2.4GHz\", \"5GHz\"],\n",
    "  \"protocol\":\"WP3\"\n",
    "}\n",
    "\n",
    "Text: Google Pixel 7, 5G network, 8GB RAM, Tensor G2 processor, 128GB of storage, Lemongrass\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpspa8CzDM20"
   },
   "source": [
    "### WiFi troubleshooting with constraints\n",
    "\n",
    "In this example, you ask the generative model to answer a question about troubleshooting a Google WiFi router based on the description of the different status lights on the router. The model will only be able to respond with the text that was provided, which helps to prevent it from generating potentially harmful or incorrect answers. Here is how you can do this using the PaLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "RmzlnDMBDM20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a network error.\n",
      "Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the question using the text below. Respond with only the text provided.\n",
    "Question: What should I do to fix my disconnected WiFi? The light on my Google WiFi router is yellow and blinking slowly.\n",
    "\n",
    "Text:\n",
    "Color: No light\n",
    "What it means: Router has no power or the light was dimmed in the app.\n",
    "What to do:\n",
    "Check that the power cable is properly connected to your router and to a working wall outlet.\n",
    "If your device is already set up and the light appears off, check your light brightness settings in the app.\n",
    "If there's still no light, contact WiFi customer support.\n",
    "\n",
    "Color: Solid white, no light, solid white\n",
    "What it means: Device is booting up.\n",
    "What to do:\n",
    "Wait for the device to boot up. This takes about a minute. When it's done, it will slowly pulse white, letting you know it's ready for setup.\n",
    "\n",
    "Color: Slow-pulsing white\n",
    "What it means: Device is ready for set up.\n",
    "What to do:\n",
    "Use the Google Home app to set up your router.\n",
    "\n",
    "Color: Solid white\n",
    "What it means: Router is online and all is well.\n",
    "What to do:\n",
    "You're online. Enjoy!\n",
    "\n",
    "Color: Slowly pulsing yellow\n",
    "What it means: There is a network error.\n",
    "What to do:\n",
    "Check that the Ethernet cable is connected to both your router and your modem and both devices are turned on. You might need to unplug and plug in each device again.\n",
    "\n",
    "Color: Fast blinking yellow\n",
    "What it means: You are holding down the reset button and are factory resetting this device.\n",
    "What to do:\n",
    "If you keep holding down the reset button, after about 12 seconds, the light will turn solid yellow. Once it is solid yellow, let go of the factory reset button.\n",
    "\n",
    "Color: Solid yellow\n",
    "What it means: Router is factory resetting.\n",
    "What to do:\n",
    "This can take up to 10 minutes. When it's done, the device will reset itself and start pulsing white, letting you know it's ready for setup.\n",
    "Image Solid red light Solid red Something is wrong. Critical failure. Factory reset the router. If the light stays red, contact WiFi customer support.\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=256, top_k=1, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract from PDF\n",
    "\n",
    "In the following example we present integration of PaLM API with DocumentAI API. In the following scenario, we ask DocumentAI to provide us the OCR of a PDF file (an Non Disclosure Aggrement) and then the text of the aggrement is prompted to text-bison in order to create a structured JSON document with the most important parts of the NDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCAI_PROJECT_ID = \"dventerpriseaisearch\"\n",
    "DOCAI_LOCATION = \"eu\"  # Format is 'us' or 'eu'\n",
    "DOCAI_PROCESSOR_ID = \"b116c372f85dbbf7\"  # Processor id in Google Cloud Console DocumentAI\n",
    "DOCUMENT_PATH = \"./nda.pdf\" # Path of target document"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method, simply requests DocumentAI to OCR nda.pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_text(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    field_mask: Optional[str] = None,\n",
    "    processor_version_id: Optional[str] = None,\n",
    ") -> None:\n",
    "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    if processor_version_id:\n",
    "        # The full resource name of the processor version, e.g.:\n",
    "        # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n",
    "        name = client.processor_version_path(\n",
    "            project_id, location, processor_id, processor_version_id\n",
    "        )\n",
    "    else:\n",
    "        # The full resource name of the processor, e.g.:\n",
    "        # `projects/{project_id}/locations/{location}/processors/{processor_id}`\n",
    "        name = client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Load binary data\n",
    "    raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name, raw_document=raw_document, field_mask=field_mask\n",
    "    )\n",
    "\n",
    "    result = client.process_document(request=request)\n",
    "\n",
    "    # For a full list of `Document` object attributes, reference this page:\n",
    "    # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\n",
    "    document = result.document\n",
    "\n",
    "    # Read the text recognition output from the processor\n",
    "    print(\"The document contains the following text:\")\n",
    "    print(document.text)\n",
    "    \n",
    "    return document.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndaText = get_ocr_text(DOCAI_PROJECT_ID, DOCAI_LOCATION, DOCAI_PROCESSOR_ID, DOCUMENT_PATH, \"application/pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a suitable prompt in order to and ask PaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are lawyer and you want to extract:\n",
    "\n",
    "1. Aggrement date (key: date)\n",
    "2. First aggrement party official name (key: partyOne)\n",
    "3. Second aggrement party official name (key: partyTwo)\n",
    "4. Purpose of NDA (key: purpose)\n",
    "5. Summary of non disclosure and confidentiality (key: summary)\n",
    "6. Applicable law authority (key: court)\n",
    "\n",
    "from the following NDA text in JSON format.\n",
    "Text:\n",
    "\"\"\"\n",
    "\n",
    "prompt += ndaText\n",
    "prompt += \"\"\"\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "print(\"-------------------------------\")\n",
    "print(\n",
    "    generation_model.predict(\n",
    "        prompt, temperature=0.2, max_output_tokens=1024, top_k=40, top_p=0.8\n",
    "    ).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "text_extraction.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
